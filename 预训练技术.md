# 分布式训练

[通信原语](https://zhuanlan.zhihu.com/p/650824387)
- Broadcast： 一对多的通信原语，一个数据发送者，多个数据接收者，可以在集群内把一个节点自身的数据广播到其他节点上。
- Scatter： 一对多的通信原语，也是一个数据发送者，多个数据接收者，可以在集群内把一个节点自身的数据发散到其他节点上。与Broadcast不同的是，Broadcast把主节点0的数据发送给所有节点，而Scatter则是将数据进行切片再分发给集群内所有的节点。
- Gather： 多对一的通信原语，具有多个数据发送者，一个数据接收者，可以在集群内把多个节点的数据收集到一个节点上。
- AllGather： 多对多的通信原语，具有多个数据发送者，多个数据接收者，可以在集群内把多个节点的数据收集到一个主节点上（Gather），再把这个收集到的数据分发到其他节点上（broadcast），即收集集群内所有的数据到所有的节点上。
- Reduce： 多对一的通信原语，具有多个数据发送者，一个数据接收者，可以在集群内把多个节点的数据规约运算到一个主节点上，常用的规约操作符有：求累加和SUM、求累乘积PROD、求最大值MAX、求最小值MIN、逻辑与LAND、按位与BAND、逻辑或LOR、按位或BOR、逻辑异或LXOR、按位异或BOXR、求最大值和最小大的位置MAXLOC、求最小值和最小值的位置MINLOC等，这些规约运算也需要加速卡支持对应的算子才能生效。
- ReduceScatter： 多对多的通信原语，具有多个数据发送者，多个数据接收者，在集群内的所有节点上都按维度执行相同的Reduce规约运算，再将结果发散到集群内所有的节点上。Reduce-scatter等价于节点个数次的reduce规约运算操作，再后面执行节点个数的scatter次操作。其反向操作是AllGather。
- AllReduce： 多对多的通信原语，具有多个数据发送者，多个数据接收者，在集群内的所有节点上都执行相同的Reduce操作，可以将集群内所有节点的数据规约运算得到的结果发送到所有的节点上。



ZeRO-DP 主要有三个优化阶段，分别对应了模型状态中优化器状态、梯度，以及模型参数的切分，也就是通常所说的ZeRO-1/2/3ZeRO-1： 优化器状态切分（ PosP_{os}P_{os} ）：切分优化器状态到各个计算卡中，在享有与普通数据并行相同通信量的情况下，可降低4倍的内存占用。ZeRO-2： 添加梯度切分（ Pos+gP_{os+g}P_{os+g} ）：在 PosP_{os}P_{os} 的基础上，进一步将模型梯度切分到各个计算卡中，在享有与普通数据并行相同通信量的情况下，拥有8倍的内存降低能力。ZeRO-3： 添加参数切分（ Pos+g+pP_{os+g+p}P_{os+g+p} ）：在 Pos+gP_{os+g}P_{os+g} 的基础上，将模型参数也切分到各个计算卡中，内存降低能力与并行数量成线性比例，通信量大约有50%的增长。

mixed precision training
通常模型会使用float32(fp32)精度进行训练，但是随着模型越来越大，训练的硬件成本和时间成本急剧增加。而混合精度训练通过利用float16(fp16)的优点并规避缺点来进行训练。
**优点：**
1. 降低显存占用，float16比float32小一半；
2. 减少网络通信开销；3.硬件针对fp16优化，速度更快
**缺点： **
1. 下溢。对于深度学习来说，float16最大的问题是"下溢"。模型的更新通常是 ，随着模型的训练，这个值往往会很小，可能会超出float16表示的精度。结果就是：大多数的模型权重都不再更新，模型难以收敛。
2. 舍入误差。模型权重和梯度相差太大，通过梯度更新权重并进行舍入时，可能导致更新前和更新后的权重没有变化。

数据并行的核心思想是：在各个GPU上都拷贝一份完整模型，各自吃一份数据，算一份梯度，最后对梯度进行累加来更新整体模型。理念不复杂，但到了大模型场景，巨大的存储和GPU间的通讯量，就是系统设计要考虑的重点了。在本文中，我们将递进介绍三种主流数据并行的实现方式：

- DP（Data Parallelism）：最早的数据并行模式，一般采用参数服务器(Parameters Server)这一编程框架。实际中多用于单机多卡
- DDP（Distributed Data Parallelism）：分布式数据并行，采用Ring AllReduce的通讯方式，实际中多用于多机场景
- ZeRO：零冗余优化器。由微软推出并应用于其DeepSpeed框架中。严格来讲ZeRO采用数据并行+张量并行的方式，旨在降低存储。

[Megatron-DeepSpeed之模型并行与数据并行](https://blog.csdn.net/v_JULY_v/article/details/132462452)

## 数据并行（DP）

[一个经典数据并行的过程如下：](https://zhuanlan.zhihu.com/p/617133971)

1. 若干块计算GPU，如图中GPU0~GPU2；1块梯度收集GPU，如图中AllReduce操作所在GPU。
2. 在每块计算GPU上都拷贝一份完整的模型参数。
3. 把一份数据X（例如一个batch）均匀分给不同的计算GPU。
4. 每块计算GPU做一轮FWD和BWD后，算得一份梯度G。
5. 每块计算GPU将自己的梯度push给梯度收集GPU，做聚合操作。这里的聚合操作一般指梯度累加。当然也支持用户自定义。
6. 梯度收集GPU聚合完毕后，计算GPU从它那pull下完整的梯度结果，用于更新模型参数W。更新完毕后，计算GPU上的模型参数依然保持一致。聚合再下发梯度的操作，称为AllReduce。

实现DP的一种经典编程框架叫“参数服务器”(PS)，在这个框架里，计算GPU称为Worker，梯度聚合GPU称为Server。在实际应用中，为了尽量减少通讯量，一般可选择一个Worker同时作为Server。比如可把梯度全发到GPU0上做聚合。需要再额外说明几点：
- 1个Worker或者Server下可以不止1块GPU。
- Server可以只做梯度聚合，也可以梯度聚合+全量参数更新一起做

### 通讯瓶颈与梯度异步更新
DP的框架理解起来不难，但实战中确有两个主要问题：

存储开销大。每块GPU上都存了一份完整的模型，造成冗余。关于这一点的优化，我们将在后文ZeRO部分做讲解。
通讯开销大。Server需要和每一个Worker进行梯度传输。当Server和Worker不在一台机器上时，Server的带宽将会成为整个系统的计算效率瓶颈。



## 显存计算
1KB=1024字节
1字节=8位
单精度浮点数 (32位) - float32:
含义：单精度浮点数用于表示实数，具有较高的精度，适用于大多数深度学习应用。
字节数：4字节（32位）

半精度浮点数 (16位) - float16:
含义：半精度浮点数用于表示实数，但相对于单精度浮点数，它的位数较少，因此精度稍低。然而，它可以在某些情况下显著减少内存占用并加速计算。
字节数：2字节（16位）

双精度浮点数 (64位) - float64:

torch.DoubleTensor
含义：双精度浮点数提供更高的精度，适用于需要更高数值精度的应用，但会占用更多的内存。
字节数：8字节（64位）

整数 (通常为32位或64位) - int32, int64:
含义：整数用于表示离散的数值，可以是有符号或无符号的。在某些情况下，例如分类问题中的标签，可以使用整数数据类型来表示类别。
字节数：通常为4字节（32位）或8字节（64位）

[注意： 模型参数精度的选择往往是一种权衡。](https://blog.csdn.net/Johntill/article/details/132629075)使用更高精度的数据类型可以提供更高的数值精度，但会占用更多的内存并可能导致计算速度变慢。相反，使用较低精度的数据类型可以节省内存并加速计算，但可能会导致数值精度损失。
在实际应用中，选择模型参数的精度需要根据具体任务、硬件设备和性能要求进行权衡考虑。

实际上，通常情况下并没有标准的整数数据类型为int4或int8，因为这些整数数据类型不太常见，且在大多数计算机体系结构中没有直接支持。在计算机中，整数通常以字节为单位进行存储，所以int4表示一个4位的整数，int8表示一个8位的整数。

然而，近年来在深度学习领域中，出于模型压缩和加速的考虑，研究人员开始尝试使用较低位数的整数来表示模型参数。例如，一些研究工作中使用的int4、int8等整数表示法是通过量化（quantization）技术来实现的。

### 推理显存计算
模型推理（inference）通常比训练阶段要求更低的显存，因为不涉及梯度计算和参数更新等大量计算。以下是计算模型推理时所需显存的一些关键因素：

模型结构： 模型的结构包括层数、每层的神经元数量、卷积核大小等。较深的模型通常需要更多的显存，因为每一层都会产生中间计算结果。

输入数据： 推理时所需的显存与输入数据的尺寸有关。更大尺寸的输入数据会占用更多的显存。

批处理大小BatchSize： 批处理大小是指一次推理中处理的样本数量。较大的批处理大小可能会增加显存使用，因为需要同时存储多个样本的计算结果。

数据类型DType： 使用的数据类型（如单精度浮点数、半精度浮点数）也会影响显存需求。较低精度的数据类型通常会减少显存需求。

中间计算： 在模型的推理过程中，可能会产生一些中间计算结果，这些中间结果也会占用一定的显存。

要估算模型推理时所需的显存，可以按照以下步骤：

模型加载： 计算模型中所有参数的大小，包括权重和偏差。
确定输入数据尺寸： 根据模型结构和输入数据大小，计算推理过程中每个中间计算结果的大小。
选择批次大小： 考虑批处理大小和数据类型对显存的影响。
计算显存大小： 将模型参数大小、中间计算结果大小和额外内存需求相加，以得出总显存需求或者使用合适的库或工具计算出推理过程中所需的显存。

以 Llama-2-7b-hf 为例
因为全精度模型参数是float32类型, 占用4个字节，粗略计算：1b(10亿)个模型参数，约占用4G显存(实际大小：10^9 * 4 / 1024^3 ~= 3.725 GB)，那么LLaMA的参数量为7b，那么加载模型参数需要的显存为：3.725 * 7 ~= 26.075 GB

### 训练显存计算
1. 模型权重

2. 梯度（Gradients）
在训练过程中，计算梯度用于更新模型参数。**梯度与模型参数的维度相同。**

3. 优化器参数
一些优化算法（如带有动量的优化器）需要保存一些状态信息，以便在每次更新时进行调整。这些状态信息也会占用一定的显存。
比如：
采用 AdamW 优化器：每个参数占用8个字节，需要维护两个状态。意味着优化器所使用的显存量是模型权重的 2 倍；
采用 经过 bitsandbytes 优化的 AdamW 优化器：每个参数占用2个字节，相当于权重的一半；
采用 SGD 优化器：占用显存和模型权重一样。
4. 激活函数和暂时存储


![Alt text](image.png)
[Total Memory = Model Size + KV cache + Activations + ( Optimizer States + Gradients ) * Number of Trainable Parameters](https://medium.com/@manuelescobar-dev/memory-requirements-for-llm-training-and-inference-97e4ab08091b)

[M= (32/Q)∗1.2/(P∗4B)](https://www.substratus.ai/blog/calculating-gpu-memory-for-llm)
​
 
Symbol	Description
M	GPU memory expressed in Gigabyte
P	The amount of parameters in the model. E.g. a 7B model has 7 billion parameters.
4B	4 bytes, expressing the bytes used for each parameter
32	There are 32 bits in 4 bytes
Q	The amount of bits that should be used for loading the model. E.g. 16 bits, 8 bits or 4 bits.
1.2	Represents a 20% overhead of loading additional things in GPU memory.

### 量化
[用整数计算代替浮点数计算的方法就是量化。](https://www.cnblogs.com/ting1/p/18217395)
量化的基本原理是根据每个tensor的浮点型最大值和最小值，将其映射为一个固定范围的整形数值集合。映射过程：1.浮点型最大值和最小值：量化过程首先涉及确定数据（如一个张量或矩阵）中的最大值和最小值。这是为了确保量化后的数据范围可以覆盖原始数据的范围，避免重要信息的丢失。2.映射为整数：接下来，原始的浮点数被线性映射到一个整数范围内。假设你有一个浮点数数组 [1.0, 2.0, 3.0]并决定使用8位量化（取值范围为 [-127, 127]）：确定最大值 3.0 和最小值 1.0。映射公式可能类似于：将 1.0 映射到 -127，3.0 映射到 127，并相应地映射 2.0。具体映射方法会根据最大值和最小值来线性缩放整个数据集。

假设一个简单的公式：qweight=round(weight/scale)，其中qweight代表量化后权重，weight代表量化前权重，scale代表缩放因子，可以看到在进行缩放后为了将浮点型转换为整数过程中增加了round操作丢失了小数部分。在后续计算或反量化为浮点型时存在无法完全还原的情况，这就是精度损失。

### 分布式框架现在有很多不足的点，比如mllm，moe，我换一个位置编码能不能支持flash attn？

# 预训练
[首先要区分清楚和pretrain对应的到底是sft还是alignment。](https://www.zhihu.com/question/635761315/answer/3480883998)alignment包含了sft、rlhf、垂类应用以及面向应用的posttrain。pretrain包含了数据准备、数据清洗、框架构建、数据策略、pretrain训练和面向通用能力的posttrain。有的公司数据准备和初清洗会单独分出一个数据组。有的公司infra单独是一组，也可能会交给pretrain组。如果一个组只做sft，那它通常是不碰模型的纯应用组，工作可能就是标数据然后提训练任务。如果是alignment，那才是真正的模型训练组，比如我司alignment组也有接近千卡。

[预训练可以优化的地方](https://www.zhihu.com/question/637595961/answer/3483115960)


[MiniCPM](https://shengdinghu.notion.site/MiniCPM-c805a17c5c8046398914e47f0542095a)


https://www.zhihu.com/search?hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A3437052990%7D&hybrid_search_source=Entity&q=minicpm%E5%85%AC%E5%8F%B8&search_source=Entity&type=content
