# 梯度
[在空间的每一个点都可以确定无限多个方向，一个多元函数在某个点也必然有无限多个方向。因此，导数在这无限多个方向导数中最大的一个（它直接反映了函数在这个点的变化率的数量级）等于多少？它是沿什么方向达到的？描述这个最大方向导数及其所沿方向的矢量，就是我们所说的梯度。](https://www.zhihu.com/question/29151564/answer/1607285093)
梯度的本意是一个向量（矢量）， 表示某一函数在该点处的方向导数沿着该方向取得最大值，即函数在该点处沿着该方向（此梯度的方向）变化最快，变化率最大（为该梯度的模）
## 反向传播
https://blog.csdn.net/fsfjdtpzus/article/details/106256925


# 梯度下降法的神经网络容易收敛到局部最优，为什么应用广泛？
[首先问题描述不够准确。](https://www.zhihu.com/question/68109802/answer/1677007564)
1. 正因为梯度下降法 容易收敛到局部最优，所以大家几乎从来不用梯度下降做非凸优化 ，包括训练神经网络。
2. 正因为随机梯度下降法 容易逃离鞍点和泛化不好的minima（主要是sharp minima），所以随机梯度下降（SGD）和它的变种（比如Momentun、Adam）才是训练神经网络最流行的方法。

鞍点（saddle points）和泛化不好的最优点（bad/sharp minima）在深度学习里的确是广泛存在的。但这是神经网络 复杂的loss landscape带来的问题，而不是优化器带来的问题。反而，优化器是来解决问题的。
正因为saddle points和bad minima太多了，所以你才太需要随机优化了。
有很多问题在深度学习理论里有和传统机器学习和最优化理论 完全不一样的解答。很多传统观点在深度学
习里都是值得怀疑的。。
(另一个常见误解是模型大小对泛化的影响：zhihu.com/question/4348）

归纳一下：
1. 优化理论里大家更在乎的是到critical points 的收敛性，梯度逐渐收敛到0即可。至于是找到minima还是saddle points ，超纲了。
2. 机器学习里大家在乎是找到的是global minima，还是local minima。local minima意味着training loss还比较高，还没优化到位。但是global minima还是local minima 在深度学习里不重要，因为所有的minima对应的loss都差不多小。
在深度学习实践中，尤其是当使用复杂的神经网络和大规模数据集时，寻找全局最小值变得非常困难，而且可能并不总是必要的。这是因为：
- 在高维空间中，许多局部最小值的损失值可能非常接近全局最小值，从实用的角度看，这些局部最小值已经足够好了。
- 研究表明，在某些条件下（如使用足够大的神经网络），神经网络的损失函数的局部最小值在性能上可能与全局最小值非常接近。
- 因此，在深度学习中，通常不需要太过担心是否达到了全局最小值，因为多数局部最小值提供的性能已经很接近最优解了。这也是为什么在实际应用中，更多的关注点是如何避免过拟合和提高泛化能力，而不是过分追求损失函数的全局最优。
3. 深度学习里，大家很在乎saddle points附近的动力学（影响优化），大家非常在乎flat minima还是sharp minima（影响泛化）。因为saddle points附近的优化会非常慢，而minima flatness 对深度学习泛化界的影响非常大。
- 鞍点 (Saddle Points)：在深度学习的损失函数中，鞍点是指在某个点的某些方向上是局部最小值，而在其他方向上是局部最大值的点。这种点在高维空间中非常常见。在鞍点附近，梯度（即导数）可能接近零，这导致梯度下降等基于梯度的优化方法在这些点附近可能会变得非常缓慢或停滞不前，从而影响整个模型的训练效率。
- 平坦极小值和尖锐极小值 (Flat Minima and Sharp Minima)：这两个概念描述的是损失函数在局部最小值附近的形状。平坦极小值（flat minima）指的是损失函数在极小值点周围变化较缓，即参数稍有变动，损失值变化不大。尖锐极小值（sharp minima）则相反，即损失函数在极小值点周围变化剧烈，参数微小的变动可能导致损失值大幅上升。
对泛化的影响：一般认为，平坦极小值有助于模型在看不见的新数据上表现得更好，也就是说具有更好的泛化能力。这是因为在平坦极小值处，模型对输入数据的小扰动或噪声不那么敏感，因此更能抵抗过拟合。相反，尖锐极小值可能导致模型在训练数据上表现很好，但在新数据上表现差，即泛化能力弱。
因此，深度学习的研究和实践中通常非常关注如何设计和选择优化算法，以便有效地越过鞍点，以及倾向于找到平坦极小值而非尖锐极小值，以增强模型的泛化能力。这些研究帮助指导如何调整学习率、选择优化算法、以及使用正则化技术等策略，以提高模型的训练效率和泛化性能。

**Note: 鞍点逃逸问题一般指的是逃离 -first-order stationary points，其实是鞍点附近、梯度很小的区域，而不是梯度严格等于0的点。**First-order stationary points：这些点是损失函数梯度等于零的点。在这些点上，根据损失函数的一阶导数（即梯度），无法确定一个明确的下降方向，因为梯度是衡量函数值增加或减少的主要工具。在实际的深度学习应用中，由于诸如数值精度限制和实际计算的复杂性，完全达到梯度严格等于零的情况是非常罕见的。更常见的情况是，梯度非常小，接近于零，这使得优化算法难以从这些区域找到明确的下降方向，从而导致训练进程停滞不前。此外，梯度接近零的区域可能是由鞍点附近的高维特性形成的。在高维空间中，由于所涉及的参数众多，很多方向的组合可能导致梯度的累计效应非常小，即使不是每个单独的方向上的梯度都严格为零。这些区域在优化过程中是难以处理的，因为梯度信息不足以提供有效的更新方向。因此，鞍点逃逸的关注点在于如何设计和使用优化算法，使其能有效地从这些难以处理的区域中“逃离”，而不是局限于只考虑梯度严格等于零的理想情况。

所以深度学习动力学有两个非常值得研究的核心问题：
一，怎么快速逃离鞍点；
二，怎么逃离sharp minima 找到flat minima。
其理论价值是，我们可以更好地理解深度神经网络 的训练过程。其实践价值是，我们可以更有依据地调参
或者设计新的随机优化器。
很幸运的是，SGD为代表的随机优化 器在这两个问题里都有相当好的性质。
直觉上的理解其实很简单——在随机梯度噪音扰动下，优化器可以加速逃离鞍点，也可以加速逃离sharp
minima。




## Adam
[**Adam逃离鞍点很快，但是不能像SGD一样擅长寻找泛化好的flat minima。**](https://www.zhihu.com/question/323747423/answer/2576604040)


所有机器学习的初学者都必然会学习梯度下降（GD）和随机梯度下降（SGD）两个古老的优化方法。细节我就不再多言，他们大体上都可以写成如下的形式：
$$
θt=θt−1−η∇L(θt−1)\theta_{t} = \theta_{t-1} - \eta \nabla L(\theta_{t-1})\theta_{t} = \theta_{t-1} - \eta \nabla L(\theta_{t-1}) 
$$
其中 $\theta_{t} $是第t个iteration时的模型参数， $\eta$ 是学习率， $\nabla L(\theta)$ 是梯度或随机梯度。定性地理解Adam很容易。简单来说，Adam = Momentum + Adaptive Learning Rate
Momentum实际上就用过去梯度的moving average来更新参数。([我曾写过一个Momentum的简单介绍：怎么通俗易懂的理解SGD中Momentum的含义？](https://www.zhihu.com/question/395685065/answer/2535950728))。Adaptive Learning Rate则是利用过去梯度second moment信息来确定各个方向的学习率的大小——loss landscape越平坦的方向用越大的学习率来更新模型参数。所以一般就把Adam算法写成如下7行形式：
$$
gt=∇L^(θt)mt=β1mt−1+(1−β1)gtvt=β2vt−1+(1−β2)gt2m^t=mt1−β1tv^t=vt1−β2tθt+1=θt−ηv^t+ϵm^tg_{t} = \nabla \hat{L}(\theta_{t})  \\        m_{t} = \beta_{1} m_{t-1} + (1-\beta_{1}) g_{t} \\        v_{t} = \beta_{2} v_{t-1} + (1-\beta_{2}) g_{t}^{2} \\        \hat{m}_{t} = \frac{m_{t}}{1-\beta_{1}^{t}}  \\        \hat{v}_{t} = \frac{v_{t}}{1-\beta_{2}^{t}}  \\        \theta_{t+1} = \theta_{t} -  \frac{\eta}{\sqrt{\hat{v}_{t}} + \epsilon} \hat{m}_{t} g_{t} = \nabla \hat{L}(\theta_{t})  \\        m_{t} = \beta_{1} m_{t-1} + (1-\beta_{1}) g_{t} \\        v_{t} = \beta_{2} v_{t-1} + (1-\beta_{2}) g_{t}^{2} \\        \hat{m}_{t} = \frac{m_{t}}{1-\beta_{1}^{t}}  \\        \hat{v}_{t} = \frac{v_{t}}{1-\beta_{2}^{t}}  \\        \theta_{t+1} = \theta_{t} -  \frac{\eta}{\sqrt{\hat{v}_{t}} + \epsilon} \hat{m}_{t}  $$
Adam算法现在已经算很基础的知识，就不多说了。
3.  鞍点逃逸和极小值选择
这些年训练神经网络的大量实验里，大家经常观察到，Adam的training loss下降得比SGD更快，但是test accuracy却经常比SGD更差（尤其是在最经典的CNN模型里）。解释这个现象是Adam理论的一个关键。我们组的这个工作专注在两个具体问题的定量分析：1）鞍点逃逸(saddle-point escaping) 和 2）极小值选择(minima selection)。这两点分别关系着训练速度和泛化性能。

[什么是Adam?](https://www.zhihu.com/search?q=adam%20%E4%BC%98%E5%8C%96%E5%99%A8&search_source=Suggestion&utm_content=search_suggestion&type=content)所有机器学习的初学者都必然会学习梯度下降（GD）和随机梯度下降（SGD）两个古老的优化方法。细节我就不再多言，他们大体上都可以写成如下的形式：θt=θt−1−η∇L(θt−1)\theta_{t} = \theta_{t-1} - \eta \nabla L(\theta_{t-1})\theta_{t} = \theta_{t-1} - \eta \nabla L(\theta_{t-1}) 其中 θt\theta_{t}\theta_{t} 是第t个iteration时的模型参数， η\eta\eta 是学习率， ∇L(θ)\nabla L(\theta)\nabla L(\theta) 是梯度或随机梯度。定性地理解Adam很容易。简单来说，Adam = Momentum + Adaptive Learning RateMomentum实际上就用过去梯度的moving average来更新参数。

# Loss
## 交叉熵
熵：[Shannon defined the entropy as the smallest possible average size of lossless encoding of the messages sent from the source to the destination.](https://naokishibuya.medium.com/demystifying-entropy-f2c3221e2550)

二分类交叉熵损失（Binary Cross-Entropy Loss）
$L = -\frac{1}{N} \sum_{i=1}^N \left[ y_i \log(\hat{y}_i) + (1 - y_i) \log(1 - \hat{y}_i) \right]$
其中：
N 是样本数量。
y i是第 𝑖个样本的真实标签，值为 0 或 1
^yi​是模型预测第i 个样本为正类（类别 1）的概率。

多分类交叉熵损失（Categorical Cross-Entropy Loss）
$L = -\frac{1}{N} \sum_{i=1}^N \sum_{c=1}^C y_{ic} \log(\hat{y}_{ic})$

其中：
N 是样本数量。
C 是类别总数。
y ic是一个独热编码向量，表示第𝑖个样本是否属于类别c（如果属于则为 1，否则为 0）。
^yi​是模型预测第i 个样本属于类别 𝑐的概率。

**交叉熵损失函数在特定情况下表现不佳的两个主要问题：**

- 类别不平衡：
在包含多个类别的数据集中，如果某个类别的样本数量远多于其他类别，那么这个多数类别将在损失函数计算中占主导地位。这意味着模型在训练过程中会倾向于更好地识别多数类别的样本，而忽视少数类别的样本。这会导致模型对少数类别的预测表现不佳。
平衡的交叉熵损失是一种解决方法，它通过调整每个类别的权重来平衡损失函数，使得所有类别对总损失的贡献更加均衡，从而改善对少数类别的预测。
- 难易例无区分：
交叉熵损失对于所有样本的错误分类进行统一处理，不区分这些错误是由难以分类的样本（难例）还是容易分类的样本（易例）引起的。这意味着模型在学习时可能对一些容易分类的样本过拟合，而无法有效地学习那些难以分类的样本。
这种情况下，模型可能需要更多地关注那些难以正确预测的样本（即难例），但标准的交叉熵损失并不提供这种机制。

## Focal loss
Focal Loss 是为了解决类别不平衡和在面对易分类样本时过度调整模型参数的问题而设计的一种损失函数。它在交叉熵损失的基础上增加了一个调整因子，以便更多地关注那些难以分类的样本。这种方法尤其在目标检测等场景中被广泛使用，其中背景类别远多于前景目标类别。[论文中gamma=2效果最好](https://medium.com/towards-data-science/focal-loss-a-better-alternative-for-cross-entropy-1d073d92d075)
$FL(p_t) = -\alpha_t (1 - p_t)^\gamma \log(p_t)$
变量说明：
\(p_t\)：模型预测样本属于其真实类别 𝑡的概率。此值是针对真实标签类别的模型输出概率。
\( \alpha_t \)：类别权重，用于调整类别不平衡，每个类别可以有不同的权重。
\( \gamma \)：聚焦参数，用于调整易分类样本（𝑝𝑡高）的影响，使模型更加关注难以分类的样本（𝑝𝑡低）。
\( \log(p_t) \)：交叉熵损失中的对数部分，用于计算预测概率的负对数似然。

例如，如果有一个二分类任务中的样本，模型预测其为正类的概率为 0.9，且真实标签也是正类：

𝑝𝑡=0.9
假设 𝛼𝑡=0.25和 𝛾=2
计算 Focal Loss 如下：

$FL(0.9) = -0.25 \times (1 - 0.9)^2 \times \log(0.9)$
$FL(0.9) = -0.25 \times 0.01 \times (-0.105)$
$FL(0.9) = 0.0002625$$

